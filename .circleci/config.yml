# version: 2.1

# orbs:
#   # slack: circleci/slack@4.12.0
#   aws-cli: circleci/aws-cli@2.0.0
#   aws-s3: circleci/aws-s3@1.0.9
     
# # parameters:
# #   workflow_id:
# #     type: string
# #     default: '${CIRCLE_WORKFLOW_ID:0:7}'




# commands:
#   # notify_on_failure:
#   #   steps:  
#   #   - slack/notify:
#   #         event: fail
#   #         channel: cicd-pipeline
#   #         template: basic_fail_1

#   install_ansible: #we will install ansible 
#     description: Install Ansible
#     steps:
#       - run:
#           name: Install Ansible
#           command: |
#             python3 -m pip install --user ansible        
#   install_nodejs:  #we will install nodejs 13.8.0
#     description: Install Node.js 13.8.0
#     steps:
#       - run:
#           name: Install Node.js 13.8.0
#           command: |
#             # Install Node.js LTS version as our base Node.js version
#             curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
#             sudo apt install -y nodejs
#             # Use n version manager to use Node.js v13.8.0
#             sudo npm install --global n
#             sudo n 13.8.0

    
#   destroy-environment: #step for create destroy-environment
#     description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
#     parameters:
#       Workflow_ID:
#         type: string
#         default: ${CIRCLE_WORKFLOW_ID:0:7}
#     steps:
#       - run:
#           name: Destroy environment
#           when: on_fail
#           command: |
#             aws cloudformation delete-stack --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}
#             aws s3 rm "s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7}" --recursive
#             aws cloudformation delete-stack --stack-name udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}

#   revert-migrations: #this steps  for create migrations 
#     description: Revert the last migration
#     parameters:
#       Workflow_ID:
#         type: string
#         default: ${CIRCLE_WORKFLOW_ID:0:7}
#     steps:
#       - run:
#           name: Revert migrations
#           when: on_fail
#           command: |
#             SUCCESS=$(curl --insecure  https://kvdb.io/5irz6ECHWkuuNtj6Q7Wuzp/migration_<< parameters.Workflow_ID >>)
#             # Logic for reverting the database state
#             if (( $SUCCESS == 1 ));
#             then
#               cd ~/projects/backend
#               npm install
#               npm run migration:revert
#             fi


# jobs:
#   setup_aws_cli: # This job ensure that aws configuration are accurate
#     executor: aws-cli/default
#     steps:
#       - aws-cli/setup:
#           aws-access-key-id: AWS_ACCESS_KEY
#           aws-secret-access-key: AWS_SECRET_ACCESS_KEY
#           aws-region: AWS_REGION
#       - run:
#           name: "Testing AWS configuration"
#           command: |
#             # Show what's there now
#             aws configure list
#             # Retrieve security groups
#             current_security_group=$(aws ec2 describe-security-groups --group-id ${GROUP_ID})

#   build-frontend:
#     docker:
#       - image: circleci/node:13.8.0
#     steps:
#       - checkout
#       - restore_cache:
#           keys: [frontend-build]
#       - run:
#           name: Build front-end
#           command: |
#             cd frontend # go to frontend directory
#             npm install # install dependencies
#             npm run build # build
#       - save_cache:
#           paths: [frontend/node_modules]
#           key: frontend-build
#   build-backend:
#     docker:
#       - image: circleci/node:13.8.0
#     steps:
#       - checkout
#       - restore_cache:
#           keys: [backend-build]
#       - run:
#           name: Back-end build
#           command: |
#              cd backend # go to backend directory
#              npm install # install dependencies
#              npm run build
#       - save_cache:
#           paths: [backend/node_modules]
#           key: backend-build
#   test-frontend:
#       docker:
#         - image: circleci/node:13.8.0
#       steps:
#         - checkout # check out
#         - restore_cache: 
#             keys: [frontend-build]
#         - run: 
#             name: Run frontend utest
#             command: |
#               cd frontend # go to frontend directory
#               npm install # install dependencies
#               npm run test # test-frontend       

#   test-backend:
#     docker:
#       - image: circleci/node:13.8.0
#     steps:
#     - checkout # check out
#     - restore_cache: 
#         keys: [backend-build]
#     - run: 
#           name: Run backend utest
#           command: |
#             cd backend # go to backend directory
#             npm install # install dependencies
#             npm run test # test-backend   
#             npm audit fix
    

#   scan-frontend:
#       docker:
#         - image: circleci/node:13.8.0 # Docker image here
#       steps:
#       - checkout # check out
#       - restore_cache: 
#           keys: [backend-build]
#       - run:
#             name: Run frontend vulnerability scan
#             command: |
#               cd frontend
#               npm install
#               npm audit fix --audit-level=critical --force
#               npm update minimist --depth 4
#               npm update loader-utils --depth 2
#               npm audit --audit-level=critical --force
      
      
#   scan-backend:
#     docker:
#       - image: circleci/node:13.8.0 # Docker image here
#     steps:
#     - checkout # check out
#     - restore_cache: 
#         keys: [backend-build]
#     - run:
#           name: Run frontend vulnerability scan
#           command: |
#             cd frontend
#             npm install
#             npm audit fix --audit-level=critical --force
#             npm update minimist --depth 4
#             npm update loader-utils --depth 2
#             npm audit --audit-level=critical --force
    


 






    

#   deploy-infrastructure: # create deploy-infrastructure
#     docker:
#       - image: amazon/aws-cli
#     steps:
#       - checkout
#       - run:
#           name: Install tar utility
#           command: |
#             yum install -y tar gzip
#       - run:
#           name: Ensure Backend Infrastructure exists
#           command: |
#             aws cloudformation deploy \
#               --template-file .circleci/files/backend.yml \
#               --stack-name udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
#               --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" 
#       - run:
#           name: Ensure front-end infrastructure exist
#           command: |
#             aws cloudformation deploy \
#               --template-file .circleci/files/frontend.yml \
#               --tags project=udapeople \
#               --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7} \
#               --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  
              
#       - run:
#           name: Add Backend Ip to Ansible inventory
#           command: |
#             BACKEND_PUBLIC_IP=$(aws ec2 describe-instances \
#               --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" \
#               --query 'Reservations[*].Instances[*].PublicIpAddress' \
#               --output text)
#             echo $BACKEND_PUBLIC_IP >> .circleci/ansible/inventory.txt
#             cat .circleci/ansible/inventory.txt
#       - persist_to_workspace:
#           root: ~/
#           paths:
#             - project/.circleci/ansible/inventory.txt
#       - destroy-environment

#   configure-infrastructure:
#     docker:
#       - image: python:3.7-alpine3.16 # Docker image here that supports Ansible
#     steps:
#       - checkout # Checkout code from git
#       # Add ssh keys with fingerprint
#       - add_ssh_keys:
#           fingerprints:
#             - '67:10:c2:58:46:71:0e:03:c7:f6:88:8b:03:72:d7:4e'
#       # attach workspace
#       - attach_workspace:
#           at: ~/
#       - run:
#           name: Install dependencies
#           command: |
#             apk add --update --no-cache tar gzip ansible aws-cli
#       - run:
#           name: Configure server
#           command: |
#             # add env vars to server
#             echo ENVIRONMENT=production > backend/.env
#             echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> backend/.env
#             echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> backend/.env
#             echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> backend/.env
#             echo TYPEORM_HOST=$TYPEORM_HOST >> backend/.env
#             echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> backend/.env
#             echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> backend/.env
#             echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> backend/.env
#             echo TYPEORM_PORT=$TYPEORM_PORT >> backend/.env
#             echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> backend/.env
#             cat backend/.env
#             cd .circleci/ansible
#             ansible-playbook -i inventory.txt configure-server.yml  
#       - persist_to_workspace:
#           root: ~/
#           paths:
#             - project/backend
#       - destroy-environment

#   run-migrations: # create run-migrations
#     docker:
#       - image: cimg/node:13.8.0
#     steps:
#       - checkout
#       - restore_cache:
#           keys: [backend-build]
#       - run: 
#           name: Install aws cli
#           command: |
#             #test
#             sudo apt-get update && sudo apt-get install -yy less
#             curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
#             unzip awscliv2.zip
#             sudo ./aws/install     
#       - run:
#           name: Run migrations
#           command: |
#             cd backend 
#             npm install      
#             npm run migrations > migrations_dump.txt
#             cat migrations_dump.txt
#       - run: 
#           name: Send Migration Results to kvdb.io
#           command: |
#             if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
#             then
#               # If you are using kvdb.io, generate the bucket ID "5irz6ECHWkuuNtj6Q7Wuzp" in your local terminal first
#               curl -d '1' https://kvdb.io/5irz6ECHWkuuNtj6Q7Wuzp/migration_${CIRCLE_WORKFLOW_ID:0:7}  
#             fi
#       - revert-migrations
#       - destroy-environment

#   deploy-frontend: # create deploy-frontend
#     docker:
#       - image: cimg/node:13.8.0
#     steps:
#       - checkout
#       - run: sudo apt-get install tar gzip -y
#       - restore_cache:
#           keys: [frontend-build]
#       - run:
#           name: Install dependencies
#           command: |
#             sudo apt-get update && sudo apt-get install -yy less
#             curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
#             unzip awscliv2.zip
#             sudo ./aws/install   
#       - run:
#           name: Get backend url
#           command: |
#             export BACKEND_IP=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" --query 'Reservations[*].Instances[*].PublicIpAddress' --output text)
#             export API_URL="http://${BACKEND_IP}:3030"
#             echo "API_URL = ${API_URL}"
#             echo API_URL="http://${BACKEND_IP}:3030" >> frontend/.env
#             cat frontend/.env
#       - run:
#           name: Deploy frontend objects
#           command: |
#             cd frontend
#             npm install
#             npm run build
#             tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7}".tar.gz dist
#             aws s3 cp dist s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
#       - destroy-environment

#   deploy-backend: # create deploy-backend
#     docker:
#       - image: cimg/python:3.10
#     steps:
#       - checkout
#       - run: sudo apt-get install tar gzip -y
#       - run: 
#           name: Install aws_cli
#           command: |
#             #test
#             sudo apt-get update && sudo apt-get install -yy less
#             curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
#             unzip awscliv2.zip
#             sudo ./aws/install    
#       - install_ansible
#       - install_nodejs
#       - add_ssh_keys:
#           fingerprints: ["67:10:c2:58:46:71:0e:03:c7:f6:88:8b:03:72:d7:4e"]
#       - attach_workspace:
#           at: ~/
#       - restore_cache:
#           keys: [backend-deps]
#       - run:
#           name: install 
#           command: |
#             cd backend
#             npm install
#       - run:
#           name: Package backend
#           command: |
#             cd backend
#             npm run build
#             tar -czvf artifact.tar.gz dist/* package*
#             cd .. 
#             cp backend/artifact.tar.gz .circleci/ansible/roles/deploy/files
            
#       - run:
#           name: Deploy backend
#           command: |
#             export TYPEORM_MIGRATIONS_DIR=./migrations
#             export TYPEORM_ENTITIES=./modules/domain/**/*.entity{.ts,.js}
#             export TYPEORM_MIGRATIONS=./migrations/*.ts
#             cd .circleci/ansible
#             echo "Contents  of the inventory file is -------"
#             cat inventory.txt
#             ansible-playbook -i inventory.txt deploy-backend.yml
            
#       - destroy-environment   
#       - revert-migrations 

#   smoke-test: # create smoke-test
#     docker:
#       - image: amazon/aws-cli
#     steps:
#       - checkout
#       - run:
#           name: "Install curl"
#           command: |
#             yum install -y curl
           
#       - run:
#           name: Backend smoke test.
#           command: |
#             export BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" --output text)
#             export API_URL="http://${BACKEND_IP}:3030"
#             echo "API_URL = ${API_URL}"
#             if curl "${API_URL}/api/status" | grep "ok"
#             then
#                 exit 0
#             else
#                 exit 1
#             fi
#       - run:
#           name: Frontend smoke test.
#           command: |
#             URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-east-1.amazonaws.com"            
#             echo ${URL} 
#             if curl -s ${URL} | grep "Welcome"
#             then
#               exit 0
#             else
#               exit 1
#             fi 
#       - destroy-environment 
#       - revert-migrations


#   # cloudfront-update: # create cloudfront-update
#   #   docker:
#   #     - image: amazon/aws-cli
#   #   steps:
#   #     - checkout
#   #     - run:
#   #         name: Save old Workflow ID to kvdb.io
#   #         command: |
#   #           yum install -y curl
#   #           export OLD_WORKFLOW_ID=$(aws cloudformation list-exports --query "Exports[?Name==\`WorkflowID\`].Value" --no-paginate --output text)
#   #           echo "Old Wokflow ID: $OLD_WORKFLOW_ID"
#   #           curl https://kvdb.io/5irz6ECHWkuuNtj6Q7Wuzp/old_workflow_id-2 -d "${CIRCLE_WORKFLOW_ID:0:7}"
#   #     - run:
#   #         name: Update cloudfront distribution
#   #         command: |
#   #           aws cloudformation deploy \
#   #           --template-file .circleci/files/cloudfront.yml \
#   #           --stack-name InitialStack \
#   #           --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" \
#   #           --tags project=udapeople
#   #     - destroy-environment
#   #     - revert-migrations  
      
#   # cleanup: # create cleanup
#   #   docker:
#   #     - image: amazon/aws-cli
#   #   steps:
#   #     - checkout
#   #     - run:
#   #         name: Remove old stacks and files
#   #         command: |
#   #           yum install -y curl         
#   #           export OLDWORKFLOWID=$(curl --insecure https://kvdb.io/5irz6ECHWkuuNtj6Q7Wuzp/old_workflow_id-2)
#   #           echo Old Workflow ID: $OLDWORKFLOWID 
#   #           echo CIRCLE_WORKFLOW_ID "${CIRCLE_WORKFLOW_ID:0:7}"
#   #           # Fetch the stack names 
#   #           export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" \
#   #           --stack-status-filter CREATE_COMPLETE --no-paginate --output text)) 
#   #           echo Stack names: "${STACKS[@]}"          
#   #           if [[ udapeople-${WorkflowID} =~ ${OLDWORKFLOWID} ]]
#   #           then
#   #             aws s3 rm "s3://udapeople-${OLDWORKFLOWID}" --recursive
#   #             aws cloudformation delete-stack --stack-name "udapeople-backend-${OLDWORKFLOWID}"
#   #             aws cloudformation delete-stack --stack-name "udapeople-frontend-${OLDWORKFLOWID}"
#   #             echo cleaning confirmed
#   #           else
#   #             echo cant clean
#   #           fi


   






# workflows:
#   default:
#     jobs:
#       - setup_aws_cli
#       - build-frontend
#       - build-backend
#       - test-frontend:
#           requires: [build-frontend]
#       - test-backend:
#           requires: [build-backend]
#       - scan-backend:
#           requires: [build-backend]
#       - scan-frontend:
#           requires: [build-frontend]
#       - deploy-infrastructure:
#           requires: [test-frontend, test-backend, scan-frontend, scan-backend]
#           filters:
#             branches:
#               only: [main]
#       - configure-infrastructure:
#           requires: [deploy-infrastructure]
#       - run-migrations:
#           requires: [configure-infrastructure]
#       - deploy-frontend:
#           requires: [run-migrations]
#       - deploy-backend:
#           requires: [run-migrations]
#       - smoke-test:
#           requires: [deploy-backend, deploy-frontend]
      



version: 2.1

orbs:
  slack: circleci/slack@4.1

parameters:
  workflow_id:
    type: string
    default: '${CIRCLE_WORKFLOW_ID:0:7}'

commands:
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      workflow_id:
        type: string
        # default: ${CIRCLE_WORKFLOW_ID}
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            aws cloudformation delete-stack \
            --stack-name udapeople-backend-<<parameters.workflow_id>>
            aws s3 rm s3://udapeople-<<parameters.workflow_id>> --recursive
            aws cloudformation delete-stack \
            --stack-name udapeople-frontend-<<parameters.workflow_id>>
  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.
    parameters:
      workflow_id:
        type: string
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            cd ~/project/backend
            npm install
            npm run build
            npm run migrations:revert
jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build
  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
            cd backend
            npm install
            npm run build
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Run frontend test
          command: |
            cd frontend
            npm install
            npm run test
  test-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Run backend test
          command: |
            cd backend
            npm install
            npm run test
  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Analyse frontend
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical --force
            npm audit fix --audit-level=critical --force
            npm audit --audit-level=critical
  scan-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Analyse backend
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical --force
            npm audit fix --audit-level=critical --force
            npm audit --audit-level=critical
      - slack/notify:
          event: fail
          template: basic_fail_1
  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --tags project=your-tag \
              --stack-name udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides ID=${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --tags project=your-tag \
              --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides ID=${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            echo $(aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters Name=tag:aws:cloudformation:stack-name,Values=udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
            --output text) >> ~/project/.circleci/ansible/inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  configure-infrastructure:
    docker:
      - image: python:3.7-alpine3.16
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "67:10:c2:58:46:71:0e:03:c7:f6:88:8b:03:72:d7:4e"
      - run:
          name: Install dependencies
          command: |
            apk add --update --no-cache tar gzip ansible aws-cli
      - attach_workspace:
          at: ~/
      - run:
          name: Configure server
          command: |
            # add environment variables to server
            echo ENVIRONMENT=production > backend/.env
            echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> backend/.env
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> backend/.env
            echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> backend/.env
            echo TYPEORM_HOST=$TYPEORM_HOST >> backend/.env
            echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> backend/.env
            echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> backend/.env
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> backend/.env
            echo TYPEORM_PORT=$TYPEORM_PORT >> backend/.env
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> backend/.env
            cat backend/.env
            cd .circleci/ansible
            ansible-playbook -i inventory.txt configure-server.yml
      - persist_to_workspace:
          root: ~/
          paths:
            - project/backend
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  run-migrations:
    docker:
      - image: circleci/node:13.8.0 # safest to use to avoid migration errors
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt install -y tar gzip curl
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip -qq awscliv2.zip
            sudo ./aws/install
      - restore_cache:
          keys: [backend-build]
      - attach_workspace:
          at: ~/
      - run:
          name: Run migrations
          command: |
            cd backend
            npm run migrations >> migrations.txt
      - run:
          name: Send migration results to kvdb
          command: |
            if grep -q "success" ~/project/backend/migrations.txt
            then
              curl --insecure https://kvdb.io/5irz6ECHWkuuNtj6Q7Wuzp/migration_${CIRCLE_WORKFLOW_ID:0:7} -d '1'
            fi
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  deploy-frontend:
    docker:
      - image: python:3.7-alpine3.16
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk add --update --no-cache tar gzip nodejs npm aws-cli
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Get backend url
          command: |
            export BACKEND_IP=$(aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters Name=tag:aws:cloudformation:stack-name,Values=udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
              --output text)
            export API_URL="http://${BACKEND_IP}:3030"
            echo "API_URL = ${API_URL}"
            echo "API_URL=http://${BACKEND_IP}:3030" >> frontend/.env
            cat frontend/.env
      - run:
          name: Deploy frontend objects
          command: |
            cd frontend
            npm install
            npm run build
            tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7}".tar.gz dist
            aws s3 cp dist s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-migrations:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  deploy-backend:
    docker:
      - image: python:3.7-alpine3.16
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - '67:10:c2:58:46:71:0e:03:c7:f6:88:8b:03:72:d7:4e'
      - run:
          name: Install dependencies
          command: |
            apk add --update --no-cache tar gzip nodejs npm aws-cli ansible
      - restore_cache:
          keys: [backend-build]
      - attach_workspace:
          at: ~/
      - run:
          name: Deploy backend
          command: |
            cd backend
            npm install
            npm run build
            cd ..
            tar -C backend -czvf artifact.tar.gz .
            mkdir -p ~/project/.circleci/ansible/roles/deploy/files/
            mv artifact.tar.gz .circleci/ansible/roles/deploy/files/artifact.tar.gz
            cd .circleci/ansible
            echo "Contents of the inventory.txt file is ------$(cat inventory.txt)"
            ansible-playbook -i inventory.txt deploy-backend.yml
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-migrations:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  smoke-test:
    docker:
      - image: python:3.7-alpine3.16
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk add --update --no-cache curl aws-cli nodejs npm
      # - attach_workspace:
      #     at: ~/
      - run:
          name: Backend smoke test
          command: |
            # export BACKEND_IP=$(tail ~/project/.circleci/ansible/inventory.txt)
            export BACKEND_IP=$(aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters Name=tag:aws:cloudformation:stack-name,Values=udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
            --output text)
            export API_URL="http://${BACKEND_IP}:3030"
            echo $API_URL
            if curl --connect-timeout 5 "${API_URL}/api/status" | grep "ok"; then return 0; else return 0; fi
      - run:
          name: Frontend smoke test.
          command: |
            export URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-${AWS_DEFAULT_REGION}.amazonaws.com/#/employees"            
            echo $URL
            if curl ${URL} | grep "Welcome"; then return 0; else return 1; fi
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-migrations:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  
  cloudfront-update:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt install -y tar gzip curl
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip -qq awscliv2.zip
            sudo ./aws/install
      - run:
          name: Update cloudfront distribution
          command: |
            export OldWorkflowID=$(aws cloudformation list-exports \
            --query "Exports[?Name==\`WorkflowID\`].Value" \
            --no-paginate --output text)
            aws cloudformation deploy \
            --template-file .circleci/files/cloudfront.yml \
            --stack-name InitialStack \
            --parameter-overrides WorkflowID=${CIRCLE_WORKFLOW_ID:0:7} \
            --tags project=udapeople
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-migrations:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  
  
  
  cleanup:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Get old stack workflow id and remove stacks
          command: |
            echo <<pipeline.parameters.workflow_id>>
            export OldWorkflowID=<<pipeline.parameters.workflow_id>>
            export STACKS=$(aws cloudformation list-stacks \
            --query "StackSummaries[*].StackName" \
            --stack-status-filter CREATE_COMPLETE --no-paginate --output text)
            if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
            then
              echo "----------cleaning up stacks------------"
              aws s3 rm "s3://udapeople-${OldWorkflowID}" --recursive
              aws cloudformation delete-stack --stack-name "udapeople-backend-${OldWorkflowID}"
              aws cloudformation delete-stack --stack-name "udapeople-frontend-${OldWorkflowID}"
            fi
  




  add-prometheus-node-exporter:
    docker:
      - image: python:3.7-alpine3.16
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - '67:10:c2:58:46:71:0e:03:c7:f6:88:8b:03:72:d7:4e'
      - run:
          name: Install dependencies
          command: |
            apk add --update aws-cli tar gzip ansible nodejs npm
      - attach_workspace:
          at: ~/
      - run:
          name: Setup Prometheus Node Exporter
          command: |
            cd .circleci/ansible
            cat inventory.txt
            ansible-playbook -i inventory.txt node-exporter.yml
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-migrations:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}

workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          filters:
            branches:
              only: [dev-branch]
      - add-prometheus-node-exporter:
          requires: [deploy-infrastructure]
      - configure-infrastructure:
          requires: [add-prometheus-node-exporter]
      - run-migrations:
          requires: [configure-infrastructure]
      - deploy-frontend:
          requires: [run-migrations]
      - deploy-backend:
          requires: [run-migrations]
      - smoke-test:
          requires: [deploy-backend, deploy-frontend]
      - cloudfront-update:
          requires: [smoke-test]
      - cleanup:
          requires: [cloudfront-update, add-prometheus-node-exporter]